# ğŸµ Trilha Sonora - Detector de Ambiente

Sistema para detectar e classificar descriÃ§Ãµes de ambiente em textos usando Small Language Models (SLM) da DeepSeek rodando localmente.

## ğŸš€ CaracterÃ­sticas

- **ğŸ”’ 100% Local**: Executa completamente offline sem envio de dados
- **âš¡ SLM Eficiente**: Usa DeepSeek R1 (1.5B parÃ¢metros) via Ollama
- **ğŸ¯ Especializado**: Classifica 8 tipos diferentes de ambiente
- **ğŸ’° Gratuito**: Sem custos de API
- **ğŸ”§ FÃ¡cil de usar**: Interface Python simples

## ğŸ“‹ Tipos de Ambiente Detectados

1. **Jardim/Ãrea Verde**: jardins, parques, plantas
2. **Ambiente DomÃ©stico**: casa, sala, cozinha, quarto
3. **Paisagem Natural**: floresta, montanha, campo
4. **Ambiente Urbano**: cidade, rua, prÃ©dios
5. **Ambiente de Trabalho**: escritÃ³rio, fÃ¡brica, loja
6. **Ambiente Rural**: fazenda, sÃ­tio, agricultura
7. **Ambiente AquÃ¡tico**: rio, lago, mar, piscina
8. **NÃ£o descreve ambiente**: textos sem descriÃ§Ã£o de local

## ğŸ› ï¸ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- Git

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/trilha-sonora.git
cd trilha-sonora
```

### 2. Criar ambiente virtual

```bash
# Linux/macOS
python -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

### 3. Instalar dependÃªncias Python

```bash
# Instalar dependÃªncias principais
pip install -r requirements.txt

# OU usando o pyproject.toml
pip install -e ./backend

# Para desenvolvimento (opcional)
pip install -e "./backend[dev]"
```

### 4. Instalar e configurar Ollama

#### Linux/macOS:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### Windows:
1. Baixe o instalador: https://ollama.com/download
2. Execute o instalador
3. Abra um novo terminal

### 5. Iniciar Ollama

```bash
ollama serve
```

### 6. Baixar modelo DeepSeek

```bash
# Modelo recomendado (1.5B parÃ¢metros)
ollama pull deepseek-r1:1.5b

# Modelos alternativos (maiores, mais precisos)
# ollama pull deepseek-r1:7b
# ollama pull deepseek-r1:14b
```

## ğŸ”¥ Uso RÃ¡pido

### Teste bÃ¡sico

```bash
cd backend
python utils/ambiente.py
```

### Usar no seu cÃ³digo

```python
from backend.utils.ambiente import DetectorAmbienteLocal

# Inicializar detector
detector = DetectorAmbienteLocal()

# Analisar texto
resultado = detector.analisar("O jardim estava cheio de flores coloridas")

# Verificar resultado
if resultado["descreve_ambiente"]:
    print(f"Ambiente: {resultado['tipo_ambiente']}")
    print(f"ConfianÃ§a: {resultado['confianca']:.2f}")
    print(f"Elementos: {resultado['elementos_identificados']}")
```

### FunÃ§Ã£o helper

```python
from backend.utils.ambiente import detectar_ambiente

# Uso direto
resultado = detectar_ambiente("A cozinha estava bem organizada")
print(resultado)
```

## ğŸ“– Exemplos

### Exemplo 1: Ambiente Natural
```python
texto = "As montanhas se estendiam atÃ© onde a vista alcanÃ§ava, cobertas de nÃ©voa matinal"
resultado = detectar_ambiente(texto)
# Output: {"tipo_ambiente": "paisagem natural", "confianca": 0.95}
```

### Exemplo 2: Ambiente DomÃ©stico
```python
texto = "Ele abriu a porta da cozinha e viu a mesa posta"
resultado = detectar_ambiente(texto)
# Output: {"tipo_ambiente": "ambiente interno domÃ©stico", "confianca": 0.88}
```

### Exemplo 3: NÃ£o Ã© ambiente
```python
texto = "O relatÃ³rio foi entregue ontem pela manhÃ£"
resultado = detectar_ambiente(texto)
# Output: {"tipo_ambiente": "nÃ£o descreve ambiente", "confianca": 0.92}
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Alterar modelo

```python
# Usar modelo maior (mais preciso, mais lento)
detector = DetectorAmbienteLocal(modelo="deepseek-r1:7b")

# Usar URL personalizada do Ollama
detector = DetectorAmbienteLocal(
    modelo="deepseek-r1:1.5b",
    ollama_url="http://192.168.1.100:11434"
)
```

### AnÃ¡lise em lote

```python
textos = [
    "O jardim estava florido",
    "A reuniÃ£o foi no escritÃ³rio",
    "O relatÃ³rio foi aprovado"
]

resultados = detector.analisar_multiplos(textos)
for resultado in resultados:
    print(f"{resultado['tipo_ambiente']}: {resultado['confianca']:.2f}")
```

## ğŸ§ª Executar Testes

```bash
# Testes bÃ¡sicos
cd backend
python utils/ambiente.py

# Testes com pytest (se instalou dependÃªncias de dev)
pytest tests/

# Testes com cobertura
pytest --cov=backend tests/
```

## ğŸ› SoluÃ§Ã£o de Problemas

### Ollama nÃ£o estÃ¡ rodando
```bash
# Verificar se estÃ¡ rodando
curl http://localhost:11434/api/tags

# Se nÃ£o estiver, iniciar
ollama serve
```

### Modelo nÃ£o encontrado
```bash
# Listar modelos instalados
ollama list

# Instalar modelo necessÃ¡rio
ollama pull deepseek-r1:1.5b
```

### Erro de memÃ³ria
```bash
# Usar modelo menor
ollama pull deepseek-r1:1.5b

# Ou ajustar configuraÃ§Ã£o do Ollama
export OLLAMA_NUM_PARALLEL=1
export OLLAMA_MAX_LOADED_MODELS=1
```

### DependÃªncias Python
```bash
# Reinstalar dependÃªncias
pip install --upgrade -r requirements.txt

# Verificar versÃ£o do Python
python --version  # Deve ser 3.8+
```

## ğŸ“Š Performance

| Modelo | ParÃ¢metros | RAM necessÃ¡ria | Velocidade | PrecisÃ£o |
|--------|-----------|----------------|------------|----------|
| deepseek-r1:1.5b | 1.5B | ~2GB | âš¡âš¡âš¡ | â­â­â­ |
| deepseek-r1:7b | 7B | ~8GB | âš¡âš¡ | â­â­â­â­ |
| deepseek-r1:14b | 14B | ~16GB | âš¡ | â­â­â­â­â­ |

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- [DeepSeek](https://www.deepseek.com/) pelos excelentes modelos SLM
- [Ollama](https://ollama.com/) pela ferramenta incrÃ­vel de execuÃ§Ã£o local
- Comunidade open source pelos modelos e ferramentas

## ğŸ“ Suporte

- ğŸ› [Reportar bug](https://github.com/seu-usuario/trilha-sonora/issues)
- ğŸ’¡ [Sugerir funcionalidade](https://github.com/seu-usuario/trilha-sonora/issues)
- ğŸ“§ Email: seu.email@exemplo.com

---

Feito com â¤ï¸ usando DeepSeek SLM e Ollama